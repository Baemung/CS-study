# 알고리즘
1. 알고리즘 분석
	1. 시간 복잡도와 공간복잡도
	2. 알고리즘의 정당성 증명
2. [알고리즘 설계 패러다임](#알고리즘-설계-패러다임)
	1. 완전 탐색
	2. [분할 정복](#분할-정복)
	3. [동적 계획법](#동적-계획법)
	4. 탐욕법
	5. 조합 탐색
	6. [파라메트릭 서치](#파라메트릭-서치)
3. [유명한 알고리즘](#유명한-알고리즘)
	1. 수치해석
	2. [정수론](#정수론)
		1. [소수](#소수)
		2. [유클리드 알고리즘](#유클리드-알고리즘)
		3. [모듈라 연산](#모듈라-연산)
	3. 계산 기하
4. 기초 자료구조
	1. 비트마스크
	2. 부분 합
	3. 선형 자료 구조
	4. 큐와 스택, 데크
	5. 문자열
5. 트리(#트리)
	1. [트리의 구현과 순회](#트리의-구현과-순회)
	2. 이진 검색트리
	3. 우선순위 큐와 힙
	4. 구간 트리
	5. 상호 배타적 집합
	6. [트라이](#트라이(Trie))
6. [그래프](#그래프)
   1. [그래프의 표현과 정의](#그래프의-표현과-정의)
   2. [DFS](#DFS)
   3. [BFS](#BFS)
   4. [최단 경로 알고리즘](#최단-경로-알고리즘)
      1. [다익스트라](#다익스트라)
      2. 벨만-포드
      3. 플로이드의 모든 쌍 최단 거리 알고리즘
   5. 최소 스패닝 트리
      1. 크루스칼의 최소 스패닝 트리 알고리즘
      2. 프림의 최소 스패닝 트리 알고리즘
   6. 네트워크 유량
      1. 포드-풀커슨 알고리즘
      2. 네트워크 모델링
      3. 이분 매칭
7. 정렬
	1. 삽입 정렬, 선택 정렬, 버블 정렬
	2. 병합 정렬
	3. 힙 정렬
	4. 퀵 정렬
	5. 기수 정렬
	6. 계수 정렬
	7. 셸 정렬

<br>

# 알고리즘 설계 패러다임
# 분할 정복
## 분할 정복(Divide and Conquer)이란?
한 문제를 둘 이상의 **부분 문제(sub-problem)** 로 나누어 해결하고 이를 합쳐 원래 문제를 해결하는 기법

분할 정복 알고리즘은 다음과 같이 세 부분으로 나누어서 생각해볼 수 있다.

1. **분할(Divide)** : 원래 문제를 분할하여 더 작은 하위 문제들 나눈다.

2. **정복(Conquer)** : 하위 문제 각각을 재귀적으로 해결

3. **병합(merge)** : 하위 문제들의 답을 합쳐서 원래 문제를 해결
 
<br>

분할 정복을 적용하기 위해서는 문제에 다음과 같은 몇 가지 특성이 성립해야 한다.

1. 부분 문제로 나누는 자연스러운 방법이 있어야 한다.

2. 부분 문제의 답을 조합해 원래 문제의 답을 계산하는 효율적인 방법이 있어야 한다.

   *(분할 정복을 사용한다고 무작정 효율이 좋아지는 것은 아니다.)*

<br>

## 분할 정복의 장/단점
- 장점 👍
  - 문제를 나눔으로써 어려운 문제를 해결할 수 있다는 장점이 있다. 그리고 이 방식이 그대로 사용되는 효율적인 알고리즘들도 여럿 있으며, 문제를 나누어 해결한다는 특징상 병렬적으로 문제를 해결하는 데 큰 강점이 있다.
  - 보통, 분할 정복의 경우 작은 문제로 분할함으로써 같은 작업을 더 빠르게 처리할 수 있게 해준다. (수행 시간 감소)

- 단점 👎
  - 함수를 재귀적으로 호출한다는 점에서 함수 호출로 인한 오버헤드가 발생하며, 스택에 다양한 데이터를 보관하고 있어야 하므로 스택 오버플로우가 발생하거나 과도한 메모리 사용을 하게 되는 단점이 있다.

<br>

## 일반적인 재귀 호출과 다른 점 

<p align="center">
<img src="https://user-images.githubusercontent.com/33649908/131237135-fd55bdac-c852-4681-b3f3-a6c4093fff28.png" width="50%">
</p>

* 분할 정복이 일반적인 재귀 호출과 다른 점은 **문제를 한 조각과 전체를 나누는 대신 거의 같은 크기의 부분 문제로 나누는 것** 이다.

* 보통 재귀 함수를 사용해서 분할 정복 알고리즘을 구현하지만, 분할 정복이라고 해서 반드시 재귀 함수를 이용하는 것은 아니다. 함수 호출시 발생하는 오버헤드를 없애기 위해서 스택이나 큐 등을 이용하는 경우도 있다.

<br>

## 분할 정복 알고리즘 활용 예시

분할 정복이 쓰이는 예는 **이분검색, 병합정렬, 퀵정렬, 최대값 찾기, 임계값의 결정, 쉬트라센 행렬곱셈 알고리즘** 등이 있다.

<br>

### 병합 정렬과 퀵정렬 (같은 문제를 어느 단계에서 해결하느냐에 따른 구분)

병합 정렬(merge sort)과 퀵 정렬(quick sort)은 분할 정복 패러다임을 기반으로 해서 만들어진 대표적인 정렬 알고리즘이다.

이 두 알고리즘은 같은 아이디어로 정렬을 수행하지만 시간이 많이 걸리는 작업을 **분할 단계**에서 하느냐, **병합 단계**에서 하느냐가 다르다.

이렇게 같은 문제를 해결하는 알고리즘이더라도 어떤 식으로(어느 단계에서) 분할하느냐에 따라 다른 알고리즘이 될 수 있다.

<br>

### 병합 정렬

<p align="center">
<img src="https://user-images.githubusercontent.com/33649908/131238392-d6591d56-4690-48b0-83c9-7e027e2fcda4.png" width="40%">
</p>

* 전체 수행 시간은 **병합 과정**에 의해 지배된다.

* **O(n)** 시간이 걸리는 과정을 **재귀 호출 후에 진행** (병합 과정)

   문제의 수는 항상 절반으로 나눠지기 때문에 필요한 단계 수는 **O(logn)**

* 시간 복잡도 : 항상 **O(nlogn)** 으로 일정

<br>

### 퀵 정렬
<p align="center">
<img src="https://user-images.githubusercontent.com/33649908/131238476-bd4f5db7-48f1-41f2-bca7-f888cb02f133.png" height="200"> <img src="https://user-images.githubusercontent.com/33649908/131238219-42fd1206-d152-4924-bfa2-0f53e122fe58.png" height="200">
</p>

* 전체 수행 시간은 두개 부분 문제로 나누는 **파티션(partition) 과정**에 의해 지배된다. 분할된 두 부분 문제가 비슷한 크기로 비슷한 크기로 나눠진다는 보장이 없기 때문에, 이를 비슷한 크기로 나누는 좋은 기준을 선택하는 것은 퀵정렬에서 중요한 요소이다.

* **O(n)** 시간이 걸리는 과정을 **재귀 호출 전**에 진행 (분할)

   문제의 수가 항상 절반으로 나누어 진다는 보장이 없기 때문에 필요한 단계수를 정확히 계산하기 힘들다.
   
   **최악의 경우 n, 평균적인 경우 logn**만큼의 단계가 필요하다.

* 시간 복잡도 : 최악 = **O(n^2)**, 평균 = **O(nlogn)**

<br>

### 관련 문제
[백준 1629번 곱셈](https://www.acmicpc.net/problem/1629)

[백준 10830번 행렬 제곱](https://www.acmicpc.net/problem/10830)

<br>

# 동적 계획법
## 동적 계획법(Dynamic Programming, DP)이란?

동적 계획법은 주어진 문제를 풀기 위해서, 문제를 여러 개의 **하위 문제(subproblem)** 로 나누어 푼 다음, 그것을 결합하여 해결하는 방식이다.

<br>

<p align="center">
<img src="https://user-images.githubusercontent.com/33649908/131238559-1a8c7588-3713-475d-b740-69629b9b9fb4.png" width="50%">
</p>

동적 계획법은 처음 주어진 문제를 더 작은 문제들로 나눈 뒤 각 조각의 답을 계산하고, 이 답들로부터 원래 문제에 대한 답을 계산해 낸다는 점에서 분할 정복(Divide and Conquer)과 비슷하다. 하지만 가장 큰 차이점은 **동적 계획법에서는 쪼개진 작은 문제가 중복되지만, 분할 정복은 절대로 중복될수가 없다는 점**이다.

다시 말하면, 동적 계획법과 분할 정복의 차이는 **문제를 나누는 방식**이다. 동적 계획법에서는 어떤 부분 문제는 두 개 이상의 문제를 푸는데 사용될 수 있기 때문에, 이 문제의 답을 여러 번 계산하는 대신 **한 번만 계산하고 그 결과를 재활용함으로써 속도를 향상**시킬 수 있다. 이때 이미 계산한 값을 저장해 두는 메모리를 캐시(cache)라고 부르며, 두 번 이상 계산되는 부분 문제를 중복되는 **부분 문제(overlapping subproblems)** 라고 부른다.

<br>

* **동적 계획법의 조건**

   두 가지 속성을 만족해야 동적 계획법으로 문제를 풀 수 있다.

1. **Overlapping Subproblem**
   : 중복되는 부분 문제(overlapping subproblem) 는 어떤 문제가 여러 개의 부분 문제(subproblem)으로 쪼개질 수 있을 때 사용하는 용어이다. 이때 '부분 문제'란, 항상 새로운 부분 문제를 생성해내기 보다는 계속해서 같은 부분 문제가 여러 번 재사용되거나 재귀 알고리즘을 통해 해결되는 문제를 가리킨다.

2. **Optimal Substructure**
   : 최적 부분구조(optimal substructure)는 어떤 문제의 최적의 해결책이 그 부분 문제의 최적의 해결책으로 부터 설계될 수 있는 경우를 말한다. 즉, 최적 부분구조 일때 문제의 정답을 작은 문제의 정답에서부터 구할 수 있다. 이 속성은 동적 계획법이나 그리디 알고리즘의 유용성을 판별하는데 사용되기도 한다.
   
<br>

* **메모리제이션(Memorization)**

메모이제이션은 컴퓨터 프로그램이 동일한 계산을 반복해야 할 때, **이전에 계산한 값을 메모리에 저장함**으로써 동일한 계산의 반복 수행을 제거하여 **프로그램 실행 속도를 빠르게 하는 기술**이다. 동적 계획법의 핵심이 되는 기술이다.

동적 계획법에서 각 문제는 한 번만 풀어야 한다. (중복되는 부분 문제를 여러번 풀지 않는다는 뜻) Optimal Substructure를 만족하기 때문에 같은 문제는 구할 때마다 정답이 같다. 따라서 정답을 한 번 구했으면 그 정답을 캐시에 메모해놓는다. 이렇게 메모하는 것을 코드의 구현에서는 배열에 저장하는 것으로 할 수 있다. 이를 메모리제이션이라고 한다.

<br>

## 동적 계획법의 장/단점

- 장점 👍
  - 필요한 모든 가능성을 고려해서 구현하므로 항상 최적의 결과를 얻을 수 있다.
  
  - 메모리에 저장된 값을 사용하므로 큰 문제를 빠른 속도로 해결하여 최적의 해를 찾아낼 수 있다.

- 단점 👎
  - 모든 가능성에 대한 고려가 불충분할 경우 최적의 결과를 보장할 수 없다.
  
  - 다른 방법론에 비해 많은 메모리 공간을 요구한다.
  
<br>

## 동적 계획법의 구현 방법

동적 계획법의 구현 방식에는 두 가지 방법이 있다.

1. **Top-down** : 큰 문제를 작은 문제로 쪼개면서 푼다. **재귀**로 구현
2. **Bottom-up** : 작은 문제부터 차례대로 푼다. **반복문**으로 구현

Top-down과 Botton-up의 시간복잡도 차이는 문제에 따라 다를 수 있으므로 정확히 알 수는 없다. Top-down은 재귀 호출을 하기때문에 스택의 사용으로 시간이 더 걸릴 것이라고 생각할 수 있겠지만, 실제로 그 차이는 크지 않다. 

(다만, 파이썬의 경우 재귀 호출 시 스택 오버 플로우(stack overflow)가 발생할 수 있기 때문에, Bottom-up으로 구현하는 것이 좋다. C++과 Java에서는 재귀로 구현하는 것이 크게 문제가 되지 않는다.)

💡 Top-down으로만 해결가능하거나 Bottom-up으로만 해결가능한 문제는 극히 드문 경우이므로, 아무거나 선택해서 사용하면 된다.

피보나치 수열을 예로 들면 다음과 같다.

* Top-down 방식
``` java
f (int n) {
  if n == 0 : return 0
  elif n == 1: return 1
  if dp[n] has value : return dp[n]
  else : dp[n] = f(n-2) + f(n-1)
         return dp[n]
}
```

* Bottom-up 방식
``` java
f (int n){
  f[0] = 0
  f[1] = 1
  for (i = 2; i <= n; i++) {
   f[i] = f[i-2] + f[i-1]
  }
  return f[n]
}
```
<br>

## 동적 계획법의 활용 예시

동적 계획법의 예시로는 **피보나치 수열 구하기, 이항계수 구하기, 최단경로의 플로이드 알고리즘, 최적화 문제, 외판원 문제** 등이 있다.

<br>

### 관련 문제
[백준 2294번 동전2](https://www.acmicpc.net/problem/2294)

[백준 1463번 1로 만들기](https://www.acmicpc.net/problem/1463)

<br>

----

# 파라메트릭 서치
결정 문제란 예 아니오 형태의 답만이 나오는 문제들을 가리킨다.

어떤 문제에서 최대가 되는 k를 구하려는 최적화 문제를 결정 문제로 바꾸는 것은 다음과 같다.

__1. k가 x이상일때 문제가 해결되는지?__

__2. 문제 해결이 안된다면 y값을 조절시켜 변경된 x이상일 때는 문제가 해결되는지?__

__3. x값 조절은 이분법을 사용__

위 과정을 반복하면 x는 문제가 해결되는 최적의 값으로 수렴하게 된다.

이렇게 결국 원래 문제인 최대값 k를 구할 수 있다. 같은 매커니즘으로 최솟값도 찾을 수 있는데, 이러한 알고리즘을 일명 파라메트릭 서치라고 부른다.

x값 조절을 이분법으로 하기 때문에, 바이너리 서치와 매우 유사하다.

하지만 차이점이 있는데, 바이너리 서치는 찾고자하는 특정한 값과 정렬된 검색 공간의 가운데에 있는 원소를 비교하여 해당 값을 찾으면 리턴, 못 찾으면 -1을 리턴해준다.

파라메트릭 서치는 특정한 값을 찾는것이 아니라 검색 공간의 가운데 값이 해당 값이 문제를 해결할 수 있는지 판단하고 범위를 좁히는데, 파라메트릭 서치는 바이너리 서치와 다르게 특정한 목표값이 없기 때문에 중간에 리턴을 할 수가 없고 반드시 값이 수렴하기 때문에 -1을 리턴하지 않는다는 차이가 있다. 

아래 문제는 파라메트릭 서치로 해결할 수 있는 가장 간단한 문제들 중 하나이다.

> __n개의 줄을 잘라서 길이(k)가 모두 동일한 m개의 줄로 만들 때, 잘라진 줄의 길이 k의 최대값을 구하라.__
> 
> __항상 n ≦ m 이며, n는 1이상 10,000이하의 정수이고, m은 1이상 1,000,000이하의 정수이다.__
> 
> __그리고 주어진 n개의 줄의 최대 길이는 2^31 - 1보다 작거나 같은 자연수이다.__
>
> __테스트 케이스로 n = 4, m = 11__
>
> __n개의 줄의 길이는 각각 802, 743, 457, 539가 주어졌다.__

최대의 k을 찾는 위 최적화 문제를 k가 x라면 줄을 m개 만들 수 있나? 라는 결정문제로 바꾸어서 풀 수 있다.

__1. k가 x라면 줄을 m개 만들 수 있나?__

__2. m개를 만들 수 없을때, x값을 줄임.__

__3. m개를 만들 수 있을때, x값을 늘림.__

__4. y+1이 m개를 만들 수 없으면 y가 k가 됨__

파라메트릭 서치 문제를 풀 때 초기 정의역x를 반드시 유효한 답을 도출할 수 있도록 잡아야 한다.

parametric_search(int min, int max) 에서  일반적으로 min은 0으로 잡으면 되고 max값을 넉넉히 잡으면 좋다.

위 문제 같은 경우는 만약 n = 4, m = 4이고, n개의 줄이 800, 1, 1, 1같은 테스트 케이스를 고려하면,

k = 200이 되므로 일반적으로 max범위는 n의 줄 길이 중 최대 길이인 800로 잡으면 된다.

```
// 수도코드
parametric_search(min, max){
	if(min > max) return max; // 기저조건, 값이 수렴

	x = (min + max)/2; // 범위 조절, 판단을 위한 x값을 정의
	
	// 있다 -> x값을 늘림 (최적값 수렴)
	// 없다 -> x값을 줄임
	if(isPossible(x)) return parametric_search(x+1, max);
	else return parametric_search(min, x-1);
}

isPossible(x){
	// 일반적으로 결정 판단을 위한 값을 구할때, 이 문제보다 훨씬 난이도가 높고 복잡하다.
	count = 0; // 결정 판단을 위한 값
	for(rope_length : rope_list) 
		count += rope_length / x; // x로 몇개의 줄을 만들 수 있는지
	
	// m개를 만들 수 있다, 없다
	if(count >= m) retrun true;
	else return false;
}
```

재귀의 기저조건인 if(min > max) return max;는 문제마다 차이가 있다.

어떤 문제는 if(min > max) return min; 일수도 있기 때문에 무조건 위 조건을 따라선 안되고 해당 문제를 이해하고 알맞은 조건을 기저조건으로 설정하여야 한다.

그리고 일반적으로 min은 left 또는 start, max는 right 또는 edn, x는 pivot 또는 mid 라는 변수명을 사용한다. 

지금 까지 본 문제는 파라메트릭 서치의 개념을 설명하기 위한 기초적인 문제였다면, 아래문제는 파라메트릭 서치의 응용 문제라고 할 수 있다. 

응용 문제같은 경우는 애초에 파라메트릭 서치 알고리즘을 이용해서 문제를 풀어야겠다는 아이디어 자체를 떠올리기가 쉽지않다...

[백준 1300번 : K번째 수](https://www.acmicpc.net/problem/1300)

[백준 12015번 : 가장 긴 증가하는 부분 수열 2](https://www.acmicpc.net/problem/12015)

# 유명한 알고리즘

# 정수론
정수론(Number Theory)은 각종 수의 성질을 대상으로 하며 기하학, 대수학, 해석학과 함께 수학의 주요한 분야들 중 하나이다. 

정수론의 현실 세계에서의 쓰임새는 다른 수학 분야에 비해 적지만, 컴퓨터가 발달되면서 사용빈도가 늘었다. 암호학의 기본 이론도 이 정수론을 기본으로 하고 있으며, 정보와 관련된 이론들도 상당 부분 정수론을 기본으로 한다. 

그 이유는 컴퓨터에서 정수는 정확한 값을 가질 수 있기 때문이다. 실수형 타입의 경우에는 round off error 때문에 오차가 생기고, 이 오차는 계산을 거듭할수록 걷잡을 수 없이 커지기 때문이다.
게다가 컴퓨터에서의 수 표현은 수를 표현할 저장공간의 한계상 정수론에서 말하는 시계 산술을 사용한다.

이름은 '정수론'이지만 기초 수준에서는 정수보다는 자연수, 그중에서도 소수를 중점적으로 다룬다. 자연수는 1과 소수, 그리고 합성수로 이루어져 있는데, 합성수들은 소수의 곱으로 생각할 수 있기 때문에 결국 소수가 다른 정수들보다 더 중요한 대우를 받게 된다.

음의 정수는 잘 다뤄지지 않는데, 대부분의 곱셈에 관련된 문제에서 양의 정수에 -1을 곱하는 것으로 음의 정수를 다룰 수 있기 때문이다. 

## 소수
소수를 한마디로 설명하면, 1보다 큰 자연수 중 1과 자기 자신만을 약수로 가지는 수라고 할 수 있다.

애초에 전제조건이 1보다 큰 자연수 중이기 때문에, 당연히 1은 소수가 아니다.

산술의 기본 정리(모든 양의 정수는 유일한 소인수 분해를 갖는다.)의 '1보다 큰 모든 자연수는 그 자체가 소수이거나, 순서를 무시하고 유일한 소인수의 조합을 갖는다'는 내용을 바탕으로 자연수는 1과 소수, 그리고 합성수로 구분된다. 

이 합성수들은 소수의 곱으로 생각할 수 있기 때문에 결국 2이상의 모든 수들은 소수들로 구성되어 있다고 볼 수 있다.

Problem Solving을 하다 보면, 소수와 관련된 문제들을 자주 접할 수 있다. 소수는 경우에 따라 변하지 않으므로 N 이하의 소수는 이미 정해져 있기 때문에, 이 이미 정해진 대량의 소수들을 빠르게 구할 수 있는 방법들이 존재한다.

그 중 대표적인 방법으로 에라토스테네스의 체가 있다. 여기서 체는 대수학에서 사용하는 유리수의 집합, 실수의 집합, 복소수의 집합을 유리수체(體), 실수체(體), 복소수체(體)라고 부르는 Field가 아닌 가루나 액체를 거를 때 사용되는 도구를 뜻한다. 

지구의 크기를 처음으로 계산해 낸 수학자로도 유명한 고대 그리스의 수학자 에라토스테네스가 만들어 낸 특정 범위 내의 소수를 구하는 방법으로, 소수가 아닌 수를 거르는 방법이 마치 체로 치듯이 수를 걸러낸다고 하여 '에라토스테네스의 체'라고 부른다고 한다. 

에라토스테네스의 체로 소수를 찾는 방법은 아래와 같다.

<p align="center"><img src="https://user-images.githubusercontent.com/51703260/131170962-794ff277-21b4-458b-bddf-86522bd05895.gif"></p>

만약 100만 이하의 소수들을 모두 구한다고 하자.

1. 2를 제외한 2의 배수들은 모두 제거한다.
2. 3을 제외한 3의 배수들은 모두 제거한다.
3. 제거 되지 않은 가장 작은 수를 제외한 해당 수의 배수를 제거한다.
4. 100만의 제곱근인 1000까지만 체크하여 해당 수들의 배수들을 모두 제거한다.

위 과정이 끝나고 제거되지 않은 수들이 100만 이하의 소수가 된다.

여기서 중요한 점은 에라토스테네스의 체를 이용해 N 이하의 소수를 구하고 싶다면, N까지 배수들을 찾아 볼 필요는 없이 N의 제곱근까지만 체크하면 된다. 

만약 N보다 작은 합성수 M이 있을 때, M = A * B 라면 A와 B 중 적어도 하나는 N의 제곱근 보다 작다. 즉, M은 N의 제곱근 이하에서 이미 배수체크가 가능해지고 소수가 걸러진다.

같은 논리로 결국 N 또한 N의 제곱근이하에서 이미 배수체크가 완료되어 소수가 다 걸러지게 된다.

```
// 수도코드
eratosthenes(N){
	isPrime = boolean[N+1]; // 0 ~ N 까지 논리형 배열
	isPrime.fill(true); // 전부 true로 초기화 (그냥 이렇게 초기화가 가능하다고 가정)
	isPrime[0] = isPrime[1] = false; // 0과 1은 소수가 아님
	
	for(i = 2; i <= sqrt(N); i++){ // N의 제곱근 까지만 체크
		if(!isPrime[i]) continue; // 소수가 아니면 continue
		for(j = i*i; j <= N; j += i){
			isPrime[j] = false; // i의 제곱부터 시작해서 i의 배수는 모두 소수가 아님.
		}			    // i * 2부터 시작해도 되지만 어차피 i가 sqrt(N)까지 접근하기 때문에 동일함
	}
	
	return isPrime;
}

main(){
	N = 1000000;
	isPrime = eratosthenes(N);
	for(i = 0; i <= N; i++){
		if(isPrime[i]) print(i);
	}
}
```
다만 에라토스테네스의 체는 '특정 범위 내의 소수'를 구하는 데에만 효율적이다.

만약 주어진 수 하나가 소수인가? 만을 따지는 상황이라면 에라토스테네스의 체 보다 비교도 안되게 빠른방법이 넘쳐난다.

아래 문제는 에라토스테네스의 체를 이용해서 해결할 수 있는 기본적인 소수를 구하는 문제와 약간 응용한 문제들이다.

[백준 1929번 : 소수 구하기](https://www.acmicpc.net/problem/1929)

[백준 4948번 : 베르트랑 공준](https://www.acmicpc.net/problem/4948)

[백준 9020번 : 골드바흐의 추측](https://www.acmicpc.net/problem/9020)


## 유클리드 알고리즘

유클리드 알고리즘은 우리에게 유클리드 호제법이라고 더 알려져있다.

수학자 유클리드에 의해 기원전 300년경에 발견된 이 알고리즘은 주어진 두 수 사이에 존재하는 최대공약수를 구하는 알고리즘이다.

이 알고리즘의 원리는 아래와 같다.

만약 임의의 두 자연수 A와 B의 최대공약수를 구한다고 하자.

1. A를 B로 나눈 나머지 M을 구한다. M = A % B
2. 이 때 A가 B보다 작으면 M은 A가 된다. (굳이 A와 B의 대소 반별이 필요없다는 의미)
3. 만약 A가 B보다 커서 M == 0 가 된다면 B가 최대 공약수가 된다.
4. 만약 M이 0이 아니면, A에 B값을 넣고, B에 M값을 넣어서 다시 1.의 M = A % B 연산을 하여 M이 0이 될 때 까지 반복한다.

```
// 수도코드
// 재귀
euclid(A, B){	
 	return B == 0 ? A : euclid(B, A % B);
}

// 반복문
euclid(A, B){ 
	while(B != 0){
		A = B;
		B = A % B;
	}
	return A;
}
```

A와 B의 최대공약수를 구했으면, A와 B의 최소공배수는 A * B / (A와B의 최대공약수)로 구할 수 있다

아래 문제는 유클리드 호제법을 이용해서 해결할 수 있는 기본적인 문제이다.

[백준 1934번 : 최소공배수](https://www.acmicpc.net/problem/1934)

## 모듈라 연산

몇 가지 중요한 암호 시스템은 계산 결과가 항상 0 - (M-1) 범위에있는 경우 모듈라 연산을 사용한다고 한다.

이때 M이 우리가 %를 하고자 하는 모듈라 값이다.

아래는 modular를 mod를 표현한 우리가 기본적으로 알고있는 모듈라 연산이다

43 mod 6 = 1

27 mod 9 = 0

3 mod 20 = 3

50 mod 17 = 16

그리고 음수의 경우에도 모듈러 연산이 가능하다.

-13 mod 11 = 9

-10 mod 11 = 1

일반적으로 수학적으로 나머지는 양수라고 약속했기 때문에 음수를 mod 할 경우에는 양수라 생각하고 mod를 한 값의 음수에서 + m을 해주면 된다.

예를 들어 -13 mod 11이면 13 mod 11 = 2 에서 -2 + 11 = 9와 같다.

하지만 프로그래밍을 할 때 A % B 에서 A 또는 B가 음수가 되면 결과는 어떻게 될까?

놀랍게도 답은 ["구현마다 다르다(Implementation-defined)"](https://en.wikipedia.org/wiki/Modulo_operation#In_programming_languages
)

당장 파이썬에서 -10 % 4는 2가 출력되고 10 % -4는 -2가 출력된다.

그리고 C++17 -10 % 4는 -2가 출력된다. 그렇기 때문에 음수 모듈라 연산을 할 때는 언어별로 다르다는 점을 미리 고려해야 할 것 같다.

## 모듈라 합동

모듈라 연산에 이해했다면 모듈라 합동에 대해서도 알면 좋을것 같다.

__(A mod M) = (B mod M) => A ≡ B (mod M)__

어떤 값 A와 B가 M으로 나누었을 때 나머지가 같다면 A와 B는 모듈라 M에 대한 합동 관계라고 표현한다.

여기서 A와 B는 A - B를 하였을 때, M의 배수가 된다.

다시 말해 A - B = K * M (K는 임의의 정수)이다.

예를 들어 13 % 6 = 1이고, 25 % 6 = 1이므로, 13과25는 모듈라 6에 대한 합동이라고 말할 수 있다.

아래 문제는 이 모듈라 합동에 관련된 문제이다.

[백준 2981번 : 검문](https://www.acmicpc.net/problem/2981)

## 모듈라 연산의 속성

모듈라 연산에는 재밌는 속성들이 존재한다.

먼저 (A + B) mod M = ((A mod M) + (B mod M)) mod M  이 성립한다.

그리고 (A - B) mod M = ((A mod M) - (B mod M)) mod M 이 성립하며

놀랍게도 (A * B) mod M = ((A mod M) * (B mod M)) mod M 또한 성립한다.

우리는 수학자가 아니라 공학자이므로 증명은 생략하고 위 공식을 잘 써먹기만 하면 된다.

이 공식을 잘 이용한다면 아래와 같은 문제를 풀 수 있다.

> 2^50이상은 계산할 수 없는 계산기가 존재한다.
> 
> 이 계산기는 mod 연산을 할 수 있는 기능이 탑재되어있다.
> 
> 이 때 2^90 mod 13을 구하라.

이 문제는 거듭제곱을 가지는 값을 모듈라 곱셈 속성을 이용해서 분할 정복으로 해결할 수 있다.

2^90은 2^50 * 2^40이다. 그러면 2^90 mod 13은 

(A * B) mod M = ((A mod M) * (B mod M)) mod M 를 이용하여

2^90 mod 13 = (2^50 * 2^40) mod 13 = ((2^50 mod 13) * (2^40 mod 13)) mod 13으로 변형시킬 수 있다.

계산기를 통해서 2^50 mod 13 = 4, 2^40 mod 13 = 3이라는 값은 바로 구할 수 있다고 했을 때,

결국 2^90 mod 13 = 12 mod 13 = 12라는 사실을 알 수 있다.


<br>

# 트리

# 트리의 구현과 순회

## 트리(Tree)

**계층적인 구조**의 자료를 표현하는 **비선형 자료구조(1:n)**

뿌리부터 잎까지의 나무를 거꾸로 뒤집어 놓은 형태를 띄며, 회사의 조직도, 파일 디렉토리 구조, 기계 학습에서의 결정 트리(decision tree) 등이 트리 구조로 표현될 수 있다.

## 트리 관련 용어

- 노드(node)와 간선(edge) : 트리의 구성 요소, 트리의 각 노드에는 데이터가 저장되고 이러한 데이터들의 연결 관계는 간선으로 나타낸다.
    - 루트(root) : 계층적인 구조에서 가장 높은 곳에 있는 노드. 한 트리에는 하나의 루트만이 존재한다.
    - 리프(leaf, 단말 노드) : 자식 노드가 존재하지 않는, 더 이상 아래로 뻗어나갈 수 없는 노드
    - 부모(parent) : 현재 노드에서 간선으로 연결된 위쪽에 있는 노드. 트리의 각 노드는 무조건 1개의 부모 노드만 가질 수 있다.
    - 자식(child) : 현재 노드에서 가지로 연결된 아래쪽 노드. 트리의 각 노드는 자식 노드를 가지지 않을 수도, 여러개의 자식 노드를 가질 수도 있다.
    - 형제(sibling) : 부모 노드가 동일한 노드들
    - 조상(ancestor) : 현재 노드에서 간선을 따라 루트노드까지 올라갈 때 연결된 모든 노드
    - 자손(descendant) : 서브 트리에 있는 하위 레벨의 노드들
- 서브 트리(subtree) : 부모 노드와 연결된 간선을 끊으면 새롭게 생성되는 트리. 하나의 트리는 여러개의 서브 트리를 포함하고 있다.

<p align="center"><img src="https://github.com/hongcheol/CS-study/blob/main/Algorithm/img/tree-degree-level.png?raw=true" alt="Tree degree and level" width="500"></p>

- 레벨(level)과 높이(height) : 루트 노드로부터 현재 노드에 이르기까지 연결된 간선의 수. 트리의 레벨의 최댓값이 트리의 높이가 된다.
- 차수(degree) : 현재 노드에 연결된 자식 노드의 수. 트리의 차수는 트리의 차수의 최댓값이다.

## 이진 트리(Binary Tree)

모든 노드가 2개의 서브 트리를 가지고 있는 트리.

## 이진 트리의 특징 

- 모든 노드는 왼쪽 자식 노드와 오른쪽 자식 노드를 각각 1개씩, 최대 2개의 노드만을 자식 노드로 가질 수 있다.(최대 차수 2)
- 공집합도 이진트리이다.
- 서브 트리 간 순서(왼쪽, 오른쪽)가 존재한다.
- 노드의 개수가 `n`개인 이진트리의 간선 개수는 `n-1`개
- 높이가 h인 이진트리의 최소 노드 개수는 `h+1`개, 최대 노드 개수는 `2^(h+1) - 1`개

## 이진 트리의 종류

![Binary Tree](https://github.com/hongcheol/CS-study/blob/main/Algorithm/img/binary-tree.png?raw=true)

### 포화 이진 트리(Full Binary Tree)

- 모든 높이에 노드가 최대로 차 있는 이진 트리
- 따라서 노드 개수는 이진 트리의 최대 노드 개수인 `2^(h+1) - 1`개
- 루트 노드를 1번으로 하여 모든 노드가 순서대로 노드 번호를 가진다.

### 완전 이진 트리(Complete Binary Tree)

- 루트 노드를 1번으로 하여 n개의 노드를 갖는 이진 트리에서 1번부터 n번까지 빈 자리가 없는 이진 트리
- 낮은 높이에서 시작하여 왼쪽 자식 노드부터 채워야 한다.

### 편향 이진 트리(Skewed Binary Tree)

- 높이 h에 대한 최소 개수의 노드를 가지며 한 쪽 방향의 자식 노드만을 가진 이진 트리
- 따라서 노드 개수는 이진 트리의 최소 노드 개수인 `h+1`개

## 이진 트리 표현

### 배열을 이용한 표현

n개의 노드를 갖는 이진 트리의 경우 루트 노드부터 마지막 노드까지 1번 ~ n번 번호를 매긴 뒤, 배열의 1번 인덱스부터 n번 인덱스까지 순서대로 노드를 삽입하여 구현

- 높이가 h인 이진 트리를 구현하기 위해서는 배열의 크기가 `2^(h+1)`가 되어야 한다.
    - 배열의 1번 인덱스부터 사용하므로 이진 트리의 최대 노드 개수인 `2^(h+1) - 1`개보다 1개 많은 크기
- 배열을 이용한 이진 트리는 구현이 쉽지만, 배열 원소에 대한 메모리 공간 낭비가 발생할 수 있다.
    - 편향 이진 트리의 경우 사용하지 않는 배열의 영역이 많아진다.
- 트리의 중간에 새로운 노드를 삽입하거나 삭제할 경우 배열의 크기 변경이 어려워 비효율적이다.

#### Java를 이용한 완전 이진 트리 구현 - 배열 표현법

```java
// 완전 이진 트리
class CompleteBinaryTreeArray {
    char[] nodes;         // 트리의 노드를 저장한 배열
    final int SIZE;             // 노드 개수 + 1
    int lastIndex;        // 마지막에 추가된 노드의 인덱스

    public CompleteBinaryTreeArray(int size) {
        this.SIZE = size;
        nodes = new char[SIZE+1];          // 1 ~ SIZE 번의 노드들을 저장하는 배열
    }

    public void add(char c) {
        if (lastIndex == SIZE) return;     // 배열 포화 상태
        nodes[++latIndex] = c;             // 배열에 노드 추가
    }
}
```

### 링크를 이용한 표현

이진 트리 노드 번호 성질을 이용해 각 부모 노드에 왼쪽 자식 노드와 오른쪽 자식 노드를 연결하여 표현한다. 한 노드가 두 개의 링크 필드를 갖는 형태이다.

> 💡 이진 트리 노드 번호의 성질
>- 노드 번호가 i인 노드의 부모 노드 번호 : `i/2`
>- 노드 번호가 i인 노드의 왼쪽 자식 노드 번호 : `2*i`
>- 노드 번호가 i인 노드의 오른쪽 자식 노드 번호 : `2*i + 1`
>- 레벨 n인 노드의 시작 번호 : `2^n`

- 배열 표현법의 한계인 메모리 낭비를 막을 수 있다. 이진 트리의 노드 개수만큼 노드를 생성하면 된다.
- 특정 노드를 탐색하기 위해 루트 노드부터 탐색을 시작해야 하므로 탐색이 비효율적이다.

#### Java를 이용한 완전 이진 트리 구현 - 링크 표현법

```java
// 트리의 노드
class Node {
    char data;         // 데이터 필드
    Node left;         // 왼쪽 자식 노드 링크 필드
    Node right;        // 오른쪽 자식 노드 링크 필드

    public Node(char data) {
        this.data = data;
        left = null;             // 리프 노드를 위한 초기화
        right = null;            // 리프 노드를 위한 초기화
    }
}

// 완전 이진 트리
class LinkedCompleteBinaryTree {
    Node[] binaryTree;

    public LinkedCompleteBinaryTree(int nodeCnt) {
        binaryTree = new Node[nodeCnt+1];                 // 노드 개수 + 1
    }

    public void add(int nodeCnt) {
        for (int i=1; i<=nodeCnt; i++) {
            binaryTree[i] = new Node(i);                  // 노드 생성 및 데이터 삽입
        }

        for (int i=1; i<=nodeCnt/2; i++) {
            binaryTree[i].left = binaryTree[2*i];         // 왼쪽 자식 노드 연결
            binaryTree[i].right = binaryTree[2*i+1];      // 오늘쪽 자식 노드 연결
        }
    }
}
```

## 트리의 탐색

비선형 자료구조인 트리에서 각 노드를 중복되지 않게 완전 탐색하기 위한 기법

### 너비 우선 탐색(BFS, Breadth First Search)

- 루트 노드의 자식 노드들을 우선적으로 모두 방문한 뒤, 방문했던 자식 노드들의 자식노드들을 또 다시 차례대로 방문하는 방식
- 인접한 노드에 대한 탐색이 끝나야 해당 노드들의 인접한 노드를 방문할 수 있으므로 **선입 선출 형태의 자료구조인 큐**(Queue)를 사용하여 구현할 수 있음

```java
public void bfs() {
    int lastIndex;                              // 노드의 개수 + 1
    Queue<Integer> q = new LinkedList<>();      // 탐색을 기다리는 노드를 저장할 큐
    q.offer(1);                 // 루트 노드의 인덱스

    int level = 0, size = 0;

    while(!q.isEmpty()) {
        size = q.size();        // 현재 높이(너비)에서의 모든 노드 개수

        while(size-->0) {       // 높이 별 노드들을 단계적으로 탐색
            int current = q.poll();
            
            System.out.println(current + " ");

            // 왼쪽 자식 노드 유효성 검사 후 큐에 삽입
            if (current*2 <= lastIndex) q.offer(current*2);
            // 오른쪽 자식 노드 유효성 검사 후 큐에 삽입
            if (current*2+1 <= lastIndex) q.offer(current*2+1);
        }

        level++;     // 현재 높이, 한 높이(너비) 별 탐색이 끝나면 크기 하나씩 증가
    }
}
```

### 깊이 우선 탐색(DFS, Depth First Search)

- 루트 노드에서 출발하여 한 방향으로 갈 수 있는 경로가 존재할 때까지 계속해서 깊이 탐색. 더 이상 방문할 수 있는 경로가 없으면 마지막으로 만났던 갈림길이 있던 노드로 돌아와 다른 방향의 노드를 같은 방식으로 계속해서 깊게 탐색하는 방식
- 자식의 자식의 자식 노드까지 깊게 탐색했다가 방문할 노드가 없을 경우 돌아와서 다른 자식 노드로 깊게 들어가야 하므로 **재귀**적으로 구현하거나, **후입 선출 형태의 자료구조인 스택**(Stack)을 사용하여 구현할 수 있음

```java
public void dfs(int current) {
    System.out.println(current + " ");      // 전위 순회 dfs로, 중위, 후위 순위의 경우 현재 라인의 위치만 자식 노드 중간과 마지막으로 바꿔주면 됨

    // 왼쪽 자식 노드 유효성 검사 후 재귀적 탐색
    if (current*2 <= lastIndex) dfs(current*2);
    // 오른쪽 자식 노드 유효성 검사 후 재귀적 탐색
    if (current*2+1 <= lastIndex) dfs(current*2+1);
}
```

## 트리의 순회

깊이 우선 탐색 시 트리의 노드를 순회하는 순서

### 전위 순회(preorder traversal) : VLR

노드 방문 -> 왼쪽 자식 -> 오른쪽 자식

```java
public void dfsByPreOrder() {
    System.out.print("Preorder : ");
    dfsByPreOrder(1);
    System.out.println();
}
	
private void dfsByPreOrder(int current) {
    // 현재 노드 처리
    System.out.print(nodes[current] + " ");
    // 왼쪽 자식 노드 방문
    if (current*2<=lastIndex) dfsByPreOrder(current*2);
    // 오른쪽 자식 노드 방문
    if (current*2+1<=lastIndex) dfsByPreOrder(current*2+1);
}
```

### 중위 순회(inorder traversal) : LVR

왼쪽 자식 -> 노드 방문 -> 오른쪽 자식

```java
public void dfsByInOrder() {
    System.out.print("Inorder : ");
    dfsByInOrder(1);
    System.out.println();
}

private void dfsByInOrder(int current) {
    // 왼쪽 자식 노드 방문
    if (current*2<=lastIndex) dfsByInOrder(current*2);
    // 현재 노드 처리
    System.out.print(nodes[current] + " ");
    // 오른쪽 자식 노드 방문
    if (current*2+1<=lastIndex) dfsByInOrder(current*2+1);
}
```

### 후위 순회(postorder traversal) :LRV

왼쪽 자식 -> 오른쪽 자식 -> 노드 방문

```java
public void dfsByPostOrder() {
    System.out.print("Postorder : ");
    dfsByPostOrder(1);
    System.out.println();
}

private void dfsByPostOrder(int current) {
    // 왼쪽 자식 노드 방문
    if (current*2<=lastIndex) dfsByPostOrder(current*2);
    // 오른쪽 자식 노드 방문
    if (current*2+1<=lastIndex) dfsByPostOrder(current*2+1);
    // 현재 노드 처리
    System.out.print(nodes[current] + " ");
}
```

## PS 문제 추천

[Baekjoon Online Judge > 트리의 부모 찾기](https://www.acmicpc.net/problem/11725)
[2019 KAKAO BLIND RECRUITMENT > 길 찾기 게임](https://www.welcomekakao.com/learn/courses/30/lessons/42892)


<br>


# 트라이(Trie)

키와 값을 쌍으로 갖는 연관 배열 데이터를 저장하는 트리 자료 구조

주로 자연어 처리(NLP) 분야에서 문자열 탐색을 위해 사용한다. 문자열의 각각의 문자 단위로 색인을 구축한 형태이다.

## 트라이 원리

### 트라이를 이용한 문자열 저장

![Trie Principle](https://github.com/hongcheol/CS-study/blob/main/Algorithm/img/trie-principle.png?raw=true)

<p align="center"><img src="https://github.com/hongcheol/CS-study/blob/main/Algorithm/img/trie-search.png?raw=true" alt="Trie Search" width="500"></p>

> 1. 각 노드가 배열로 구성된 트리를 생성한다.
> 2. 저장하려는 문자열의 모든 문자들을 확인하며 아래 과정을 시행한다.
> 3. 루트 노드(문자 배열)에서 문자열의 첫번째 문자에 해당하는 인덱스로 이동한다.
> 4. 해당 인덱스에 연결된 자식 노드가 존재하지 않는다면 새로운 노드(문자 배열)를 할당한다. 이후 새로운 노드에서 두번째 문자에 해당하는 인덱스로 이동한다.
> 5. 해당 인덱스에 연결된 자식 노드가 존재한다면 해당 노드의 두번째 문자에 해당하는 인덱스로 이동한다.
> 6. 문자열의 모든 문자를 다 저장할 때까지(즉, 문자열 길이만큼) 위의 과정을 반복한다. 마지막 문자를 저장하고 나서는 배열 값을 `true`로 설정하여 하나의 문자열이 완전히 저장됨을 표시한다.

위의 과정에서 주목할 점은 **접두사가 동일한 문자열**을 저장할 경우 **최소 하나 이상의 노드를 공유**한다는 것이다!

## 트라이의 시간 복잡도

위의 방식대로 문자열을 저장할 경우 **한 문자열을 탐색할 때 고작 `O(1)`의 연산**만 필요하게 된다.

아무리 트리 노드가 많이 존재하더라도, 심지어는 전세계 모든 인구인 80억명의 이름이 저장된 트라이라고 할지라도, 오직 `O(1)`의 시간만이 걸린다. 그 이유는 한 문자열을 탐색하기 위해서는 해당 문자열이 갖고 있는 문자 노드만을 탐색하기 때문이다. 루트 노드에서부터 **해당 문자열의 길이** 만큼의 자식 노드만 타고 들어가기 때문에, 다른 탐색 알고리즘과 달리 **저장된 문자열의 개수에 영향을 받지 않는다**는 점이 트라이의 큰 특장점이다.

## 트라이의 공간 복잡도

우수한 시간적 성능을 자랑하는 트라이의 치명적인 한계는 바로 메모리를 많이 사용한다는 것이다.

트라이를 이용해 한국의 5천만 인구의 이름을 저장한다고 생각해보자. 한국에서 가장 긴 이름은 `"박하늘별님구름햇님보다사랑스러우리"`로 17자이다. 이 이름을 저장하기 위해서는 한글의 모든 음절을 배열로 담은, 길이가 `11,172인 배열`이 `17개`가 필요하고 총 `189,924`만큼의 메모리(1음절을 1byte로 가정)가 필요하다. 이름의 길이가 길어서 생긴 문제라고 말할 수도 있겠지만, 가장 보편적인 3자 이름 역시 `11,172인 배열`이 `3개`가 필요하고 총 `33,516`만큼의 메모리가 필요하다. 한 명의 이름을 저장하는데도 이렇게 많은 메모리를 사용하는데 이런 방식으로 `5천만`명의 이름을 저장한다면 어마어마한 크기의 메모리가 필요하게 될 것이다.(물론 같은 성을 사용하거나 돌림자를 사용하는 이름은 노드를 같이 사용할 수 있어 조금은 효율적이라고 말할 수 있다.)

트라이의 공간 복잡도는 대략 `O(포인터 크기 * 포인터 배열의 길이 * 전체 노드 개수)`가 된다. 따라서 트라이는 **시간적 성능과 공간적 성능을 맞바꾼** 대표적인 예로 볼 수 있다.

## Java를 이용한 트라이 구현

```java
class Trie {
    final int ALPHABET_SIZE = 26;         // 포인터 배열의 길이(표현할 수 있는 문자 개수)

    class Node {
        Node[] children = new Node[ALPHABET_SIZE];     
        boolean isEndOfWord;              // 저장하려는 문자열의 마지막 문자 여부

        public Node() {
            for (int i=0; i<ALPHABET_SIZE; i++) {
                children[i] = null;       // 포인터 배열 초기화
            }

            isEndOfWord = false;          // 마지막 문자 여부 초기화
        }
    }

    Node root;                            // 문자열의 첫번째 문자

    public void insert(String key) {
        int length = key.length();        // 탐색하려는 문자열 길이
        int alphabetIdx;                  // 문자열의 각 문자의 인덱스
        Node curAlphabet = root;          // 현재 탐색중인 문자열의 문자

        for (int level=0; level<length; level++) {
            alphabetIdx = key.charAt(level) - 'a';                    // 문자열의 각 문자의 인덱스 구하기
            Node nextAlphabet = curAlphabet.children[alphabetIdx];    // 문자열의 다음 문자

            if (nextAlphabet == null) {         // 찾으려는 문자에 연결된 자식 노드가 없을 경우
                nextAlphabet = new Node();      // 새로운 노드 생성 뒤 자식 노드로 연결
            }

            curAlphabet = nextAlphabet;         // 찾으려는 문자의 자식 노드를 현재 노드로
        }

        curAlphabet.isEndOfWord = true;         // 문자열의 모든 문자에 대해 삽입이 끝났다면 마지막 문자의 노드는 true로 변경하여 하나의 문자열이 저장됐음을 표시
    }

    public boolean search(String key) {
        int length = key.length();        // 탐색하려는 문자열 길이
        int alphabetIdx;                  // 문자열의 각 문자의 인덱스
        Node curAlphabet = root;          // 현재 탐색중인 문자열의 문자

        for (int level=0; level<length; level++) {
            alphabetIdx = key.charAt(level) - 'a';
            Node nextAlphabet = curAlphabet.children[alphabetIdx];

            if (nextAlphabet == null) {         // 탐색하려는 문자열이 존재하지 않는 경우
                return false;
            }

            curAlphabet = nextAlphabet;         // 찾으려는 문자의 자식 노드를 현재 노드로
        }

        return (curAlphabet.isEndOfWord);       // 탐색하려는 문자열이 존재하는 경우
    }
}
```

## PS 문제 추천

[2020 KAKAO BLIND RECRUITMENT > 가사검색](https://programmers.co.kr/learn/courses/30/lessons/60060)

<br>



# 그래프
# 그래프의 표현과 정의
어떤 자료나 개념을 표현하는 정점(vertex)들의 집합 V와 이들을 연결하는 간선(edge)들의 집합 E로 구성된 자료구조

주로 현실 세계의 사물이나 추상적인 개념 간의 연결관계를 표현할 때 사용

## 그래프 관련 용어

- 노드 (Node): 위치를 말함, 정점(Vertex)라고도 함

- 간선 (Edge): 위치 간의 관계를 표시한 선으로 노드를 연결한 선이라고 보면 됨 (link 또는 branch 라고도 함)
- 인접 정점 (Adjacent Vertex) : 간선으로 직접 연결된 정점(또는 노드)
- 참고
  - 정점의 차수 (Degree): 무방향 그래프에서 하나의 정점에 인접한 정점의 수
  - 진입 차수 (In-Degree): 방향 그래프에서 외부에서 오는 간선의 수
  - 진출 차수 (Out-Degree): 방향 그래프에서 외부로 향하는 간선의 수
  - 경로 길이 (Path Length): 경로를 구성하기 위해 사용된 간선의 수
  - 단순 경로 (Simple Path): 처음 정점과 끝 정점을 제외하고 중복된 정점이 없는 경로
  - 사이클 (Cycle): 단순 경로의 시작 정점과 종료 정점이 동일한 경우

## 그래프의 종류

<img width="731" alt="그래프_종류" src="https://user-images.githubusercontent.com/16794320/127731827-67d5dabf-871b-4b8c-a150-07b1749593a8.png">

### 방향 그래프

그래프의 각 간선이 방향이라는 속성을 갖는 그래프

### 가중치 그래프

그래프의 각 간선이 가중치(weight)라는 송석을 갖는 그래프

### 다중 그래프

두 정점 사이에 두 개 이상의 간선이 있을 수 있는 그래프

### 트리

간선을 통해 두 정점을 잇는 방법이 딱 하나밖에 없는 그래프

### 이분그래프

그래프의 정점들을 겹치지 않는 두 개의 그룹으로 나눠서 서로 다른 그룹에 속한 정점들 사이에만 간선이 존재하도록 만들 수 있는 그래프

### DAG

사이클 없는 방향 그래프(Directed Acyclic Graph)

기본적으로 방향 그래프, 한 점에서 출발해 자기 자신으로 돌아오는 경로가 없는 경우

## 그래프의 경로

그래프에서 경로란 끝과 끝이 연결된 간선들을 순서대로 나열한 것
<img width="303" alt="그래프_경로" src="https://user-images.githubusercontent.com/16794320/127731829-9ac04786-3ff6-4711-b67f-0e3f7f12233c.png">

주어진 그림에서 1에서 5로 가는 경로는 
(1,2),(2,4),(4,5)와 같이 표현.
간단하게 1-2-4-5로도 표현

## 그래프의 표현 방법

V = 정점의 수

### 인접 리스트

그래프의 각 정점마다 해당 정점에서 나가는 간선의 목록을 저장해서 그래프를 표현

각 정점마다 하나의 연결 리스트를 갖는 방식으로 구현

### 인접 행렬

인접 리스트가 두 정점의 연결 관계를 확인하기위해 모든 리스트를 뒤져야한다는 단점 보완

|V|X|V| 크기의 행렬(|V|는 정점의 갯수)로 표현한다.

간**선의 수가 $V^2$에 비해서 훨씬 적은 경우 인접리스트를 사용하는 것이 유리하고**

**간선의 수가 $V^2$에 비례하는 경우 인접행렬을 사용하는 것이 유리하다.**

### 암시적 그래프 표현

그래프를 직접 메모리에 표현하지않고 그래프 구조만 사용하는 것이 유리한 경우

- 입력이 그래프의 형태를 띄지않는 문제의 경우(ex. 배열로 주어진 미로)
- 그래프의 크기가 아주 큰데 실제 사용하는 부분은 그래프의 일부분인 경우

# DFS

DFS(Depth-First Search,깊이 우선 탐색)은 그래프의 모든 노드를 탐색하는 가장 단순한 방법입니다.

정점의 자식들을 먼저 탐색하는 방식으로 다음의 순서를 따릅니다.

1. 현재 정점과 인접한 간선들을 하나씩 검사한다.
2. 아직 방문하지 않은 정점으로 향하는 간선이 있다면 그 간선을 따라간다.
3. 더 이상 갈 곳이 없는 막힌 정점에 도달할 때까지 반복한다.
4. 더이상 갈 곳이 없다면 가장 마지막에 지난 간선을 따라 돌아가 더 이상 방문할 정점이 없을 때까지 반복한다.

각 정점이 정수형인 경우를 예시로 설명하겠습니다.


![그래프_표](./img/graph_chart.png)

위와 같이 만들어진 그래프를 DFS로 탐색하는 그림은 다음과 같습니다.

<img src="./img/graph_DFS.png" alt="그래프_DFS" style="zoom:50%;" />


## Java로 그래프를 표현하는 방법

정점의 개수를 n, 간선의 개수를 m,  연결관계에 있는 노드를 (node1, node2)의 순서쌍으로 하면, 다음과 같이 그래프를 표현할 수 있습니다.

```java
Map<Integer, ArrayList<Integer>> graph = new TreeMap<Integer, ArrayList<Integer>>();
int n = 0, m = 0
Scanner sc = new Scanner(System.in);
n = sc.nextInt();
m = sc.nextInt();
//초기화 해줘야지 아래의 반복문에서 nullPointException 발생하지않는다.
for(int i = 0;i<n;i++){
  graph.put(i+1,new ArrayList<>());
}
for(int i = 0;i<m;i++){
  int n1 = 0, v1 = 0;
  node1 = sc.nextInt();
  node2 = sc.nextInt();
  graph.get(n1).add(node2);
  graph.get(node2).add(node1);
}
```



## DFS 알고리즘 구현

스택을 활용해서 구현할 수 있습니다.

```java
//code
public void dfsWithoutRecursion(int start) {
  Stack<Integer> stack = new Stack<Integer>();
  boolean[] isVisited = new boolean[adjVertices.size()];
  stack.push(start);
  while (!stack.isEmpty()) {
    int current = stack.pop();
    isVisited[current] = true;
    visit(current);
    for (int dest : adjVertices.get(current)) {
      if (!isVisited[dest])
        stack.push(dest);
    }
  }
}
```

재귀호출을 통해 메서드 스택을 이용해서 구현하는 방법도 있습니다.

```java
public void dfs(int start) {
  boolean[] isVisited = new boolean[adjVertices.size()];
  dfsRecursive(start, isVisited);
}
void dfsRecursive(int current, boolean[] isVisited) {
  isVisited[current] = true;
  visit(current);
  for (int dest : adjVertices.get(current)) {
    if (!isVisited[dest])
      dfsRecursive(dest, isVisited);
  }
}
```



## 시간 복잡도

일반적으로 DFS의 시간복잡도는 정점의 수를 V, 간선의 수를 E라고 할 때 O(V+E) 입니다.

# BFS

BFS(너비 우선 탐색)은 그래프를 탐색하는 방법 중 하나입니다.

정점들과 같은 레벨에 있는 노드(형제 노드)들을 먼저 탐색하는 방법으로 다음의 순서를 따릅니다. 

1. 현재 정점과 인접한 간선들을 하나씩 검사합니다.

2. 현재 노드에서 방문할 수 있는 노드를 전부 방문합니다.

3. 전부 방문한 후 그 다음 레벨의 노드를 방문합니다.

4. 더 이상 방문할 곳이 없다면 탐색을 종료합니다.

   

   ![그래프_표](./img/graph_chart.png)

<img src="./img/graph_BFS.png" alt="graph_BFS" style="zoom:50%;" />

## BFS 알고리즘 구현

queue와 배열을 이용해서 구현할 수 있습니다.

```java
//code
static void bfs(Map graph,int start_node){
  Queue<Integer> need_visit = new LinkedList<>();
  Queue<Integer> visited = new LinkedList<>();
  need_visit.add(start_node);

  while(need_visit.isEmpty()==false){
    int node = need_visit.poll();
    if(!visited.contains(node)){
      visited.add(node);
      ArrayList<Integer> temp = (ArrayList<Integer>) graph.get(node);
      for(int data : temp) need_visit.add(data);
    }
  }
  for(int data : visited)System.out.print(data+" ");
}
```



## 시간복잡도

일반적으로 BFS의 시간복잡도는 정점의 수를 V, 간선의 수를 E라고 할 때 O(V+E) 입니다.

# 최단 경로 알고리즘

### 최단 경로 문제란 무엇일까요?

최단 경로 문제란 두 노드를 잇난 가장 짧은 경로를 찾는 문제입니다. 즉, 가중치 그래프에서 간선의 가중치의 합이 최소가 되도록하는 경로를 찾는 것입니다.

그렇다면 최단 경로 문제는 어떤 종류가 있을까요??

1. 단일 출발 및 단일 도착 최단 경로 문제
2. 단일 출발 최단 경로 문제
3. 전체 쌍 최단 경로 문제

## 다익스트라

다익스트라 알고리즘은 최단 경로의 문제 종류 중 단일 출발 최단 경로 문제에 속합니다. 

그 이유는 다익스트라 알고리즘이 하나의 정점에서 다른 모든 정점 간의 가장 짧은 거리를 구하는 알고리즘이기 때문입니다.

### Basic idea

```java
//init
S = {v0}; distance[v0] = 0; 
for (w 가 V - S에 속한다면)//V-S는 전체 정점에서 이미 방문한 정점을 뺀 차집합.
	if ((v0, w)가 E에 속한다면) distance[w] = cost(v0,w); 
	else distance[w] = inf;

//algorithm
S = {v0};
while V–S != empty {
  //아래의 코드는 지금까지 최단 경로가 구해지지않은 정점 중 가장 가까운 거리를 반복한다는 의미
	u = min{distance[w], w 는 V-S의 원소};//---1
	
  S = S U {u}; 
  V–S = (V–S)–{u};
	for(vertex w : V–S)
		distance[w] = min{distance[w],distance[u]+cost(u,w)}//update distance[w];---2
}
```

위의 코드에서 1로 마킹한 부분에대한 설명을 하겠습니다.

먼저 length[v]는 최단 경로의 길이를 의미하고 distance[w]는 시작점에서부터의 최단 경로의 길이를 의미합니다.

S는 시작점을 포함해서 현재까지 최단 경로를 발견한 점들의 집합을 의미합니다.

<img src="./img/Dijkstra_0.png" alt="Dijkstra_0" style="zoom:75%;" />

u = min{distance[w], w 는 V-S의 원소}의 의미는 u까지의 최단 거리의 길이는 distance[u] 와 같다는 의미입니다. 

둘이 같다는 것은 다음처럼 증명할 수 있습니다.

![Dijkstra_1](./img/Dijkstra_1.png)

1. distance[u] > length[u]라고 가정해보겠습니다.
2. P를 시작점부터 u까지의 최단 경로라고 하면
3. P의 길이 = length[u]입니다.
4. P는 S에 속하지않는 최소 1개의 정점을 가집니다. 그렇지않다면 P의 길이 = distance[u]가 됩니다.
5. P의 경로에 속하면서 S에 속하지않는 시작점에서 가장 가까운 점을 w라 하겠습니다.
6. 그렇게 된다면 distance[u] > length[u] >= length[w] 가 성립하고, length[w] = distance[w]이기 때문에  이로부터
   **distance[u] > distance[w]**를 유추해낼 수 있습니다.
7. 이는 다익스트라 알고리즘은 아직 최단경로가 찾아지지않은 정점들만 선택한다는 정의에 어긋납니다.(지금 보는 점보다 가까운 경로가 존재한다면 이전 탐색에서 걸러져서 S에 포함되어있기 때문입니다.)

그렇기 때문에 distance[u] = length[u]입니다.

다음으로는 distance[w]를 업데이트하는 부분입니다.

<img src="./img/Dijkstra_2.png" alt="Dijkstra_2" style="zoom:50%;" />

위의 그림에서와 같이 시작점 v0에서 u를 거쳐 w로 가는 경로와 v0에서 w로 가는 경로의 길이 중 가까운 경로를 distance[w]로 설정하고 S와 V-S를 최신화해줍니다.

distance[ ]를 업데이트할 때 각각의 간선들이 2번씩 체크되는데 그 이유는 다음과 같습니다.

1. 

<img src="./img/Dijkstra_3.png" alt="Dijkstra_3" style="zoom:75%;" />

아직 최단 경로를 찾지 못한 정점 중 u에 인접한 정점들의 거리를 업데이트 할 때 u와 w를 연결하는 간선이 체크가 됩니다. 

2.

<img src="./img/Dijkstra_4.png" alt="Dijkstra_4" style="zoom:75%;" />

정점 w의 최단 경로가 찾아졌기 때문에, w는 S에 속하게됩니다. 아직 최단 경로를 찾기 못한 정점들에서 w까지의 거리를 업데이트하는 과정에서 u에서 w로의 간선이 다시 한 번 체크됩니다.



이런 방식으로 코드를 작성하면 각 정접들에대해서 u에 인접한 모든 간선을 살펴보는 연산이 추가되기 때문에 최악의 경우 시간복잡도가 O(𝑛^2)가 되버립니다. 이를 개선하는 방법으로는 대표적으로 우선순위 큐를 사용하는 방법(O( 𝑛 + 𝑚 log 𝑛))과 피보나치 힙을 사용하는 방법(O(𝑛 log 𝑛 + 𝑚))이 있습니다. 

피보나치 힙에대한 내용은 [피보나치 힙](https://en.wikipedia.org/wiki/Fibonacci_heap) 을 확인해주시고, 지금은 우선순위 큐에대한 내용을 다루겠습니다.

### 다익스트라 알고리즘 로직(우선순위 큐)

- 첫 번째 정점을 기준으로 연결되어있는 정점들을 추가해가면서 최단 거리를 갱신합니다.

  첫 정점부터 각 노드 사이의 거리를 저장하는 배열을 만든 후에 첫 정점의 인접 노드 간의 거리부터 먼저 계산하면서, 첫 정점부터 해당 노드 사이의 가장 짧은 거리를 해당 배열에 업데이트 합니다. 이런 로직은 현재의 정점에서 갈 수 있는 정점들부터 처리한다는 점에서 BFS와 비슷합니다. 

  다양한 다익스트라 알고리즘이 있지만 가장 개선된 형태인 우선순위 큐를 사용하는 방식을 다뤄보겠습니다.

  먼저 우선 순위 큐를 간단하게 설명하면 MinHeap 방식을 사용해서 현재 가장 짧은 거리를 가진 노드 정보를 먼저 꺼냅니다.

  꺼낸 노드는 다음의 과정을 반복합니다.

  1. 첫 정점을 기준으로 배열을 선언핸 첫 정점에서 각 정점까지의 거리를 저장합니다.
     - 초기에는 첫 정점의 거리를 0, 나머지는 무한대(inf)로 저장합니다.
     - 우선순위 큐에 순서쌍 (첫 정점, 거리 0) 만 먼저 넣어줍니다. 
  2. 우선순위 큐에서 노드를 꺼냅니다.
     - 처음에는 첫 정점만 저장된 상태이기때문에 첫번째 정점만 꺼내집니다.
     - 첫 정점에 인접한 노드들 각각에대해서 첫 정점에서 각 노드로 가는 거리와 현재 배열에 저장되어있는 첫 정점에서 각 정점까지의 거리를 비교합니다.
     - 배열에 저장되어 있는 거리보다, 첫 정점에서 해당 노드로 가는 거리가 더 짧은 경우, 배열에 해당 노드의 거리를 업데이트 합니다.
     - 배열에 해당 노드의 거리가 업데이트된 경우, 우선순위 큐에 해당 노드를 넣어줍니다.
  3. 2번의 과정을 우선순위 큐에서 꺼낼 노드가 없을 때까지 반복합니다.

- 우선순위 큐를 사용하면 지금까지 발견된 가장 짧은 거리의 노드에대해서 먼저 계산을 해서 더 긴 거리로 계산된 루트에 대해서는 계산을 스킵할 수 있다는 장점이 있습니다.

pseudo 코드는 다음과 같습니다. 

```java
found[], distance[]를 초기화
construct min_heap(V-{s});
for(i = 0; i < n-2; i++) { //𝑛−1iterations(=Θ(𝑛))---(1) 
  distance[u]가 최소인 정점 u를 선택합니다. //Θ(1) found[u] = T;로 바로 배열로 접근 가능
  min_heap에서 정점 u를 제거; //O(log𝑛)---(2)
  for(every vertex w adjacent to u) //Θ(𝑚)total---(a)
      if(found[w] == F && distance[u] + cost(u,w) < distance[w]){
        distance[w] = distance[u] + cost(u,w);
        adjust heap(w); //𝑂(log𝑛)foreachedgecheck---(b) 
  } // distance[w]가 수정됐기 때문에 heap을 조정해주는 for문
}
```



### 시간 복잡도

위의 pseudo code에서 다음 2가지 과정을 거칩니다.

(1),(a) - 각 정점마다 인접한 간선들을 모두 검사하는 과정 -> 𝑂(𝑛)

(2),(b) - 우선순위 큐에 정점/거리 정보를 넣고 삭제하는 과정 -> 𝑂(log𝑛)

따라서 전체 알고리즘은 O((𝑛+𝑚)log𝑛)입니다.

